{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Hierarchical econder for intent classification","metadata":{}},{"cell_type":"markdown","source":"#### Downloading dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import BertModel, BertTokenizer\n\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:01:21.747691Z","iopub.execute_input":"2023-02-19T17:01:21.748600Z","iopub.status.idle":"2023-02-19T17:01:25.905480Z","shell.execute_reply.started":"2023-02-19T17:01:21.748513Z","shell.execute_reply":"2023-02-19T17:01:25.903798Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:01:25.908207Z","iopub.execute_input":"2023-02-19T17:01:25.908584Z","iopub.status.idle":"2023-02-19T17:01:25.914727Z","shell.execute_reply.started":"2023-02-19T17:01:25.908543Z","shell.execute_reply":"2023-02-19T17:01:25.913509Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = load_dataset(\"swda\")","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:01:25.918489Z","iopub.execute_input":"2023-02-19T17:01:25.918936Z","iopub.status.idle":"2023-02-19T17:02:42.862014Z","shell.execute_reply.started":"2023-02-19T17:01:25.918899Z","shell.execute_reply":"2023-02-19T17:02:42.860936Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca90089154b148539259422036baefa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c664709bf0b4ae88ecae578889d4833"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset swda/default (download: 13.79 MiB, generated: 158.13 MiB, post-processed: Unknown size, total: 171.91 MiB) to /root/.cache/huggingface/datasets/swda/default/0.0.0/b53d17ec4c6e31d0921591dd2d8e86d15850822209a980fcddb2983fc948e499...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/14.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a06d2b6414a8490daccfa73f021a70a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98e7915197b64478b99a6649ee0edc61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fad37f9f42e84a0e84ed1877b1c543f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57424e4d31a540a9ad99f462a57b1eb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/75.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e10c28779714ca18740eec56f983210"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60668dc47be24e22b54bdbd7d36e7377"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/213543 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/56729 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/4514 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset swda downloaded and prepared to /root/.cache/huggingface/datasets/swda/default/0.0.0/b53d17ec4c6e31d0921591dd2d8e86d15850822209a980fcddb2983fc948e499. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8acaa913d254c4d82fa9eeb53d37911"}},"metadata":{}}]},{"cell_type":"code","source":"data","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-19T17:02:42.864854Z","iopub.execute_input":"2023-02-19T17:02:42.865230Z","iopub.status.idle":"2023-02-19T17:02:42.875716Z","shell.execute_reply.started":"2023-02-19T17:02:42.865192Z","shell.execute_reply":"2023-02-19T17:02:42.874729Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['swda_filename', 'ptb_basename', 'conversation_no', 'transcript_index', 'act_tag', 'damsl_act_tag', 'caller', 'utterance_index', 'subutterance_index', 'text', 'pos', 'trees', 'ptb_treenumbers', 'talk_day', 'length', 'topic_description', 'prompt', 'from_caller', 'from_caller_sex', 'from_caller_education', 'from_caller_birth_year', 'from_caller_dialect_area', 'to_caller', 'to_caller_sex', 'to_caller_education', 'to_caller_birth_year', 'to_caller_dialect_area'],\n        num_rows: 213543\n    })\n    validation: Dataset({\n        features: ['swda_filename', 'ptb_basename', 'conversation_no', 'transcript_index', 'act_tag', 'damsl_act_tag', 'caller', 'utterance_index', 'subutterance_index', 'text', 'pos', 'trees', 'ptb_treenumbers', 'talk_day', 'length', 'topic_description', 'prompt', 'from_caller', 'from_caller_sex', 'from_caller_education', 'from_caller_birth_year', 'from_caller_dialect_area', 'to_caller', 'to_caller_sex', 'to_caller_education', 'to_caller_birth_year', 'to_caller_dialect_area'],\n        num_rows: 56729\n    })\n    test: Dataset({\n        features: ['swda_filename', 'ptb_basename', 'conversation_no', 'transcript_index', 'act_tag', 'damsl_act_tag', 'caller', 'utterance_index', 'subutterance_index', 'text', 'pos', 'trees', 'ptb_treenumbers', 'talk_day', 'length', 'topic_description', 'prompt', 'from_caller', 'from_caller_sex', 'from_caller_education', 'from_caller_birth_year', 'from_caller_dialect_area', 'to_caller', 'to_caller_sex', 'to_caller_education', 'to_caller_birth_year', 'to_caller_dialect_area'],\n        num_rows: 4514\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_data = data['train']\ntrain_df = pd.DataFrame(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:02:42.876995Z","iopub.execute_input":"2023-02-19T17:02:42.877781Z","iopub.status.idle":"2023-02-19T17:03:37.302037Z","shell.execute_reply.started":"2023-02-19T17:02:42.877725Z","shell.execute_reply":"2023-02-19T17:03:37.301012Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:03:37.303683Z","iopub.execute_input":"2023-02-19T17:03:37.304084Z","iopub.status.idle":"2023-02-19T17:03:37.578355Z","shell.execute_reply.started":"2023-02-19T17:03:37.304045Z","shell.execute_reply":"2023-02-19T17:03:37.577406Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                   swda_filename ptb_basename  conversation_no  \\\n0       sw00utt/sw_0001_4325.utt     4/sw4325             4325   \n1       sw00utt/sw_0001_4325.utt     4/sw4325             4325   \n2       sw00utt/sw_0001_4325.utt     4/sw4325             4325   \n3       sw00utt/sw_0001_4325.utt     4/sw4325             4325   \n4       sw00utt/sw_0001_4325.utt     4/sw4325             4325   \n...                          ...          ...              ...   \n213538  sw11utt/sw_1115_3451.utt     3/sw3451             3451   \n213539  sw11utt/sw_1115_3451.utt     3/sw3451             3451   \n213540  sw11utt/sw_1115_3451.utt     3/sw3451             3451   \n213541  sw11utt/sw_1115_3451.utt     3/sw3451             3451   \n213542  sw11utt/sw_1115_3451.utt     3/sw3451             3451   \n\n        transcript_index  act_tag  damsl_act_tag caller  utterance_index  \\\n0                      0      115             26      A                1   \n1                      1       82             15      A                1   \n2                      2      206             36      B                2   \n3                      3      148             20      A                3   \n4                      4      148             20      B                4   \n...                  ...      ...            ...    ...              ...   \n213538               161      125              4      B               94   \n213539               162      148             20      A               95   \n213540               163      194             21      B               96   \n213541               164      176              4      B               96   \n213542               165      125              4      B               96   \n\n        subutterance_index                                               text  \\\n0                        1                                           Okay.  /   \n1                        2                                           {D So, }   \n2                        1                                     [ [ I guess, +   \n3                        1  What kind of experience [ do you, + do you ] h...   \n4                        1  I think, ] + {F uh, } I wonder ] if that worke...   \n...                    ...                                                ...   \n213538                   1                                    It really is. /   \n213539                   1                             And have enthusiasm. /   \n213540                   1                                           Yeah,  /   \n213541                   2                                   it really is.  /   \n213542                   3                                {C And } I felt, -/   \n\n        ... from_caller from_caller_sex from_caller_education  \\\n0       ...        1632          FEMALE                     2   \n1       ...        1632          FEMALE                     2   \n2       ...        1632          FEMALE                     2   \n3       ...        1632          FEMALE                     2   \n4       ...        1632          FEMALE                     2   \n...     ...         ...             ...                   ...   \n213538  ...        1415          FEMALE                     1   \n213539  ...        1415          FEMALE                     1   \n213540  ...        1415          FEMALE                     1   \n213541  ...        1415          FEMALE                     1   \n213542  ...        1415          FEMALE                     1   \n\n       from_caller_birth_year  from_caller_dialect_area to_caller  \\\n0                        1962                   WESTERN      1519   \n1                        1962                   WESTERN      1519   \n2                        1962                   WESTERN      1519   \n3                        1962                   WESTERN      1519   \n4                        1962                   WESTERN      1519   \n...                       ...                       ...       ...   \n213538                   1939             SOUTH MIDLAND      1423   \n213539                   1939             SOUTH MIDLAND      1423   \n213540                   1939             SOUTH MIDLAND      1423   \n213541                   1939             SOUTH MIDLAND      1423   \n213542                   1939             SOUTH MIDLAND      1423   \n\n       to_caller_sex  to_caller_education to_caller_birth_year  \\\n0             FEMALE                    1                 1971   \n1             FEMALE                    1                 1971   \n2             FEMALE                    1                 1971   \n3             FEMALE                    1                 1971   \n4             FEMALE                    1                 1971   \n...              ...                  ...                  ...   \n213538        FEMALE                    2                 1960   \n213539        FEMALE                    2                 1960   \n213540        FEMALE                    2                 1960   \n213541        FEMALE                    2                 1960   \n213542        FEMALE                    2                 1960   \n\n        to_caller_dialect_area  \n0                SOUTH MIDLAND  \n1                SOUTH MIDLAND  \n2                SOUTH MIDLAND  \n3                SOUTH MIDLAND  \n4                SOUTH MIDLAND  \n...                        ...  \n213538                 WESTERN  \n213539                 WESTERN  \n213540                 WESTERN  \n213541                 WESTERN  \n213542                 WESTERN  \n\n[213543 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>swda_filename</th>\n      <th>ptb_basename</th>\n      <th>conversation_no</th>\n      <th>transcript_index</th>\n      <th>act_tag</th>\n      <th>damsl_act_tag</th>\n      <th>caller</th>\n      <th>utterance_index</th>\n      <th>subutterance_index</th>\n      <th>text</th>\n      <th>...</th>\n      <th>from_caller</th>\n      <th>from_caller_sex</th>\n      <th>from_caller_education</th>\n      <th>from_caller_birth_year</th>\n      <th>from_caller_dialect_area</th>\n      <th>to_caller</th>\n      <th>to_caller_sex</th>\n      <th>to_caller_education</th>\n      <th>to_caller_birth_year</th>\n      <th>to_caller_dialect_area</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sw00utt/sw_0001_4325.utt</td>\n      <td>4/sw4325</td>\n      <td>4325</td>\n      <td>0</td>\n      <td>115</td>\n      <td>26</td>\n      <td>A</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Okay.  /</td>\n      <td>...</td>\n      <td>1632</td>\n      <td>FEMALE</td>\n      <td>2</td>\n      <td>1962</td>\n      <td>WESTERN</td>\n      <td>1519</td>\n      <td>FEMALE</td>\n      <td>1</td>\n      <td>1971</td>\n      <td>SOUTH MIDLAND</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sw00utt/sw_0001_4325.utt</td>\n      <td>4/sw4325</td>\n      <td>4325</td>\n      <td>1</td>\n      <td>82</td>\n      <td>15</td>\n      <td>A</td>\n      <td>1</td>\n      <td>2</td>\n      <td>{D So, }</td>\n      <td>...</td>\n      <td>1632</td>\n      <td>FEMALE</td>\n      <td>2</td>\n      <td>1962</td>\n      <td>WESTERN</td>\n      <td>1519</td>\n      <td>FEMALE</td>\n      <td>1</td>\n      <td>1971</td>\n      <td>SOUTH MIDLAND</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sw00utt/sw_0001_4325.utt</td>\n      <td>4/sw4325</td>\n      <td>4325</td>\n      <td>2</td>\n      <td>206</td>\n      <td>36</td>\n      <td>B</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[ [ I guess, +</td>\n      <td>...</td>\n      <td>1632</td>\n      <td>FEMALE</td>\n      <td>2</td>\n      <td>1962</td>\n      <td>WESTERN</td>\n      <td>1519</td>\n      <td>FEMALE</td>\n      <td>1</td>\n      <td>1971</td>\n      <td>SOUTH MIDLAND</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sw00utt/sw_0001_4325.utt</td>\n      <td>4/sw4325</td>\n      <td>4325</td>\n      <td>3</td>\n      <td>148</td>\n      <td>20</td>\n      <td>A</td>\n      <td>3</td>\n      <td>1</td>\n      <td>What kind of experience [ do you, + do you ] h...</td>\n      <td>...</td>\n      <td>1632</td>\n      <td>FEMALE</td>\n      <td>2</td>\n      <td>1962</td>\n      <td>WESTERN</td>\n      <td>1519</td>\n      <td>FEMALE</td>\n      <td>1</td>\n      <td>1971</td>\n      <td>SOUTH MIDLAND</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sw00utt/sw_0001_4325.utt</td>\n      <td>4/sw4325</td>\n      <td>4325</td>\n      <td>4</td>\n      <td>148</td>\n      <td>20</td>\n      <td>B</td>\n      <td>4</td>\n      <td>1</td>\n      <td>I think, ] + {F uh, } I wonder ] if that worke...</td>\n      <td>...</td>\n      <td>1632</td>\n      <td>FEMALE</td>\n      <td>2</td>\n      <td>1962</td>\n      <td>WESTERN</td>\n      <td>1519</td>\n      <td>FEMALE</td>\n      <td>1</td>\n      <td>1971</td>\n      <td>SOUTH MIDLAND</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213538</th>\n      <td>sw11utt/sw_1115_3451.utt</td>\n      <td>3/sw3451</td>\n      <td>3451</td>\n      <td>161</td>\n      <td>125</td>\n      <td>4</td>\n      <td>B</td>\n      <td>94</td>\n      <td>1</td>\n      <td>It really is. /</td>\n      <td>...</td>\n      <td>1415</td>\n      <td>FEMALE</td>\n      <td>1</td>\n      <td>1939</td>\n      <td>SOUTH MIDLAND</td>\n      <td>1423</td>\n      <td>FEMALE</td>\n      <td>2</td>\n      <td>1960</td>\n      <td>WESTERN</td>\n    </tr>\n    <tr>\n      <th>213539</th>\n      <td>sw11utt/sw_1115_3451.utt</td>\n      <td>3/sw3451</td>\n      <td>3451</td>\n      <td>162</td>\n      <td>148</td>\n      <td>20</td>\n      <td>A</td>\n      <td>95</td>\n      <td>1</td>\n      <td>And have enthusiasm. /</td>\n      <td>...</td>\n      <td>1415</td>\n      <td>FEMALE</td>\n      <td>1</td>\n      <td>1939</td>\n      <td>SOUTH MIDLAND</td>\n      <td>1423</td>\n      <td>FEMALE</td>\n      <td>2</td>\n      <td>1960</td>\n      <td>WESTERN</td>\n    </tr>\n    <tr>\n      <th>213540</th>\n      <td>sw11utt/sw_1115_3451.utt</td>\n      <td>3/sw3451</td>\n      <td>3451</td>\n      <td>163</td>\n      <td>194</td>\n      <td>21</td>\n      <td>B</td>\n      <td>96</td>\n      <td>1</td>\n      <td>Yeah,  /</td>\n      <td>...</td>\n      <td>1415</td>\n      <td>FEMALE</td>\n      <td>1</td>\n      <td>1939</td>\n      <td>SOUTH MIDLAND</td>\n      <td>1423</td>\n      <td>FEMALE</td>\n      <td>2</td>\n      <td>1960</td>\n      <td>WESTERN</td>\n    </tr>\n    <tr>\n      <th>213541</th>\n      <td>sw11utt/sw_1115_3451.utt</td>\n      <td>3/sw3451</td>\n      <td>3451</td>\n      <td>164</td>\n      <td>176</td>\n      <td>4</td>\n      <td>B</td>\n      <td>96</td>\n      <td>2</td>\n      <td>it really is.  /</td>\n      <td>...</td>\n      <td>1415</td>\n      <td>FEMALE</td>\n      <td>1</td>\n      <td>1939</td>\n      <td>SOUTH MIDLAND</td>\n      <td>1423</td>\n      <td>FEMALE</td>\n      <td>2</td>\n      <td>1960</td>\n      <td>WESTERN</td>\n    </tr>\n    <tr>\n      <th>213542</th>\n      <td>sw11utt/sw_1115_3451.utt</td>\n      <td>3/sw3451</td>\n      <td>3451</td>\n      <td>165</td>\n      <td>125</td>\n      <td>4</td>\n      <td>B</td>\n      <td>96</td>\n      <td>3</td>\n      <td>{C And } I felt, -/</td>\n      <td>...</td>\n      <td>1415</td>\n      <td>FEMALE</td>\n      <td>1</td>\n      <td>1939</td>\n      <td>SOUTH MIDLAND</td>\n      <td>1423</td>\n      <td>FEMALE</td>\n      <td>2</td>\n      <td>1960</td>\n      <td>WESTERN</td>\n    </tr>\n  </tbody>\n</table>\n<p>213543 rows Ã— 27 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Tokenization","metadata":{}},{"cell_type":"code","source":"# Load the pre-trained BERT model and tokenizer\nmodel = BertModel.from_pretrained('bert-base-uncased')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', padding=True, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:03:37.579531Z","iopub.execute_input":"2023-02-19T17:03:37.579874Z","iopub.status.idle":"2023-02-19T17:03:52.559598Z","shell.execute_reply.started":"2023-02-19T17:03:37.579835Z","shell.execute_reply":"2023-02-19T17:03:52.558584Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a81e6d7b53874ec7a0418f8035695acf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"793a47d04877405fbe3c444c25bc86ec"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79c27e2215a44d1a8ac98c884f4332bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"662873e5580c4395bbedcf6882974476"}},"metadata":{}}]},{"cell_type":"code","source":"# Define the data preprocessing function\ndef preprocess_data(utterance):\n    text = utterance['text']\n    label = utterance['act_tag']\n    return {'text': text, 'label': label}","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:03:52.564627Z","iopub.execute_input":"2023-02-19T17:03:52.566894Z","iopub.status.idle":"2023-02-19T17:03:52.577224Z","shell.execute_reply.started":"2023-02-19T17:03:52.566855Z","shell.execute_reply":"2023-02-19T17:03:52.572572Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Preprocess the data\npreprocessed_dataset = data.map(preprocess_data)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:03:52.578497Z","iopub.execute_input":"2023-02-19T17:03:52.578872Z","iopub.status.idle":"2023-02-19T17:05:01.229863Z","shell.execute_reply.started":"2023-02-19T17:03:52.578835Z","shell.execute_reply":"2023-02-19T17:05:01.228983Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/213543 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec3ca5f8fedc4a85bff1e0a147f8076b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/56729 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9df67eff60f946e5a74e20eb5f2b4482"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4514 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"631221a8cbb94812941100c8cbc5bb4b"}},"metadata":{}}]},{"cell_type":"code","source":"preprocessed_dataset = preprocessed_dataset.remove_columns(['swda_filename', 'ptb_basename', 'conversation_no', 'transcript_index', 'act_tag', 'damsl_act_tag', 'caller', 'utterance_index', 'subutterance_index', 'pos', 'trees', 'ptb_treenumbers', 'talk_day', 'length', 'topic_description', 'prompt', 'from_caller', 'from_caller_sex', 'from_caller_education', 'from_caller_birth_year', 'from_caller_dialect_area', 'to_caller', 'to_caller_sex', 'to_caller_education', 'to_caller_birth_year', 'to_caller_dialect_area'])","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:05:01.234090Z","iopub.execute_input":"2023-02-19T17:05:01.234373Z","iopub.status.idle":"2023-02-19T17:05:01.256230Z","shell.execute_reply.started":"2023-02-19T17:05:01.234347Z","shell.execute_reply":"2023-02-19T17:05:01.255406Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"preprocessed_dataset['train']['text'][:10]","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:05:01.259502Z","iopub.execute_input":"2023-02-19T17:05:01.259783Z","iopub.status.idle":"2023-02-19T17:05:01.462177Z","shell.execute_reply.started":"2023-02-19T17:05:01.259736Z","shell.execute_reply":"2023-02-19T17:05:01.461068Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['Okay.  /',\n '{D So, }',\n '[ [ I guess, +',\n 'What kind of experience [ do you, + do you ] have, then with child care? /',\n 'I think, ] + {F uh, } I wonder ] if that worked. /',\n 'Does it say something? /',\n 'I think it usually does.  /',\n 'You might try, {F uh, }  /',\n \"I don't know,  /\",\n 'hold it down a little longer,  /']"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples['text'], truncation=True, padding=True, return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:05:01.463699Z","iopub.execute_input":"2023-02-19T17:05:01.464965Z","iopub.status.idle":"2023-02-19T17:05:01.470235Z","shell.execute_reply.started":"2023-02-19T17:05:01.464926Z","shell.execute_reply":"2023-02-19T17:05:01.469192Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset = preprocessed_dataset.map(lambda examples: tokenizer(examples['text'], truncation=True, padding=True), batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:05:01.471842Z","iopub.execute_input":"2023-02-19T17:05:01.472512Z","iopub.status.idle":"2023-02-19T17:06:42.507840Z","shell.execute_reply.started":"2023-02-19T17:05:01.472443Z","shell.execute_reply":"2023-02-19T17:06:42.506795Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/214 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb80148d764b4e3f80078b215293b541"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a121635989f745788e8b8fa3dc7d3a43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2779412aff8c4148a75c3b0c6e7d4901"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_dataset['train'][0]","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:06:42.509148Z","iopub.execute_input":"2023-02-19T17:06:42.509783Z","iopub.status.idle":"2023-02-19T17:06:42.524686Z","shell.execute_reply.started":"2023-02-19T17:06:42.509731Z","shell.execute_reply":"2023-02-19T17:06:42.523098Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'text': 'Okay.  /',\n 'label': 115,\n 'input_ids': [101,\n  3100,\n  1012,\n  1013,\n  102,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'token_type_ids': [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0]}"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Defining the hierarchical encoder architecture","metadata":{}},{"cell_type":"markdown","source":"The architecture of the hierarchical encoder consists of a **BERT-based model** with a linear classification layer on top, which has been fine-tuned on the SWDA dataset for intent classification.\n\nBy using the outputs of the different layers of the BERT model, the hierarchical encoder is able to capture the hierarchical structure of natural language, and the fine-tuning process allows the model to learn task-specific representations that are optimized for intent classification.","metadata":{}},{"cell_type":"code","source":"class HierarchicalEncoder(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.mlp = nn.Sequential(\n            nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size),\n            nn.ReLU(),\n            nn.Linear(self.bert.config.hidden_size, num_classes)\n        )\n    \n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids.to(device), attention_mask=attention_mask.to(device))\n        sequence_output = outputs.last_hidden_state\n        pooled_output = torch.mean(sequence_output, dim=1)\n        logits = self.mlp(pooled_output)\n        return logits.to(device)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:06:42.526294Z","iopub.execute_input":"2023-02-19T17:06:42.526668Z","iopub.status.idle":"2023-02-19T17:06:42.603549Z","shell.execute_reply.started":"2023-02-19T17:06:42.526632Z","shell.execute_reply":"2023-02-19T17:06:42.602525Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the data collator\nfrom transformers import DataCollatorWithPadding\nlst = tokenized_dataset['train']['input_ids']\n\n\nfrom torch.nn.utils.rnn import pad_sequence\n\n# Define the data collator\ndef collate_fn(examples):\n    input_ids = pad_sequence([torch.tensor(x['input_ids']) for x in examples], batch_first=True, padding_value=tokenizer.pad_token_id)\n    attention_mask = pad_sequence([torch.tensor(x['attention_mask']) for x in examples], batch_first=True, padding_value=0)\n    labels = torch.tensor([x['label'] for x in examples])\n    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': labels}\n\n# Define the training and validation data loaders\ntrain_loader = DataLoader(tokenized_dataset['train'], batch_size=64, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(tokenized_dataset['validation'], batch_size=64, collate_fn=collate_fn)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:08:05.229020Z","iopub.execute_input":"2023-02-19T17:08:05.229389Z","iopub.status.idle":"2023-02-19T17:08:14.537364Z","shell.execute_reply.started":"2023-02-19T17:08:05.229357Z","shell.execute_reply":"2023-02-19T17:08:14.536297Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the batch_sizemodel, loss function, and optimizer\nmodel = HierarchicalEncoder(num_classes=len(data['train'].features['act_tag'].names)).to(device)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-5)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:06:57.389827Z","iopub.execute_input":"2023-02-19T17:06:57.390776Z","iopub.status.idle":"2023-02-19T17:07:03.880253Z","shell.execute_reply.started":"2023-02-19T17:06:57.390688Z","shell.execute_reply":"2023-02-19T17:07:03.879261Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model\nnum_epochs = 3\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    count = 0\n    for i, batch in enumerate(train_loader):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        logits = model(input_ids, attention_mask)\n        loss = criterion(logits, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * input_ids.size(0)\n        if (i+1) % 10 == 0:\n            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Train Loss: {loss.item():.4f}')\n\n    train_loss /= len(tokenized_dataset['train'])\n    \n    model.eval()\n    val_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            logits = model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n            val_loss += loss.item() * input_ids.size(0)\n            preds = torch.argmax(logits, axis=1)\n            correct += torch.sum(preds == labels)\n            total += input_ids.size(0)\n    val_loss /= len(tokenized_dataset['validation'])\n    val_acc = correct / total\n    \n    \n    print(f'Epoch {epoch + 1}, train loss: {train_loss:.4f}, val loss: {val_loss:.4f}, val accuracy: {val_acc:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:14:04.391874Z","iopub.execute_input":"2023-02-19T17:14:04.392976Z","iopub.status.idle":"2023-02-19T17:14:04.498023Z","shell.execute_reply.started":"2023-02-19T17:14:04.392930Z","shell.execute_reply":"2023-02-19T17:14:04.496756Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/1995394267.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_24/3037130171.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m         )\n\u001b[1;32m   1018\u001b[0m         encoder_outputs = self.encoder(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 15.90 GiB total capacity; 14.70 GiB already allocated; 31.75 MiB free; 15.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"RuntimeError","evalue":"CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 15.90 GiB total capacity; 14.70 GiB already allocated; 31.75 MiB free; 15.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}